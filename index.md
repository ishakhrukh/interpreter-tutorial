
## Make Your Own Programming Language

By Ibrahim Shakhrukh

### Table of contents
1. [Introduction](#introduction)
2. [The Interpreter](#the-interpreter)
3. [Getting Starting](#getting-started)
4. [Part One: The Tokenizer](#tokenizer)
5. [Part Two: The Parser](#parser)
6. [Part Three: Understanding How the Virtual Machine Will Work](#vm)
7. [Part Four: Code Generation](#code-generation)
8. [Part Five: The Virtual Machine](#vm)

### Introduction <a name="introduction"></a>
In this tutorial, we will be making an interpreter for our own programming language with a sytax similar to Javascript.
#### What's an interpreter?
An interpreter is a program that reads and executes programs written in a high-level language. Some famous examples are the Java Virtual Machine (JVM) and the CPython, the original python interpreter.
### The Interpreter <a name="the-interpreter"></a>
Our interpreter, like most other ones, will consist of two main parts: a compiler and a virtual machine (VM):
#### The Compiler
The compiler will involve two stages: [abstract syntax tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree) (AST) generation and [bytecode](https://en.wikipedia.org/wiki/Bytecode) generation. An AST is a tree representation of the source code and serves as the base for bytecode generation, and bytecode is an instruction set which the virtual machine will run, much like a real computer.
#### The Virtual Machine
A [virtual machine](https://en.wikipedia.org/wiki/Virtual_machine#Process_virtual_machines) simply executes the bytecode generated by the compiler. We'll go more into depth in  [Part Three: Understanding How the Virtual Machine Will Work](#vm).
### Getting Starting <a name="getting-started"></a>
For this tutorial, I will be using Python, since it's the simplest language and you can carry on the examples to other languages of your choice. However, if you're extremely concerned about performance, I suggest using a faster language, like Java or C#, or for maximum speed, a compiled language like C/C++. Oh, and by the way, Python isn't my best language, so if you see code smells or other things like that, please bare with me. Before we write the rest of our code, lets import what we need and define some functions:
```python
import sys
from enum import Enum, auto
from typing import Any

# so we don't have to add `end=''` when we need to print
# which will be used quite a bit later on
def print_raw(str):
    print(str, end='')

def compilerError(message: str):
    print('Error: ' + message, file=sys.stderr)
    exit(1)

def compilerError(line: int, col: int, message: str):
    print(f'Error (line {line}, col {col}): {message}', file=sys.stderr)
    exit(1)
```
### Part One: The Tokenizer <a name="tokenizer"></a>
In order to build an AST, we need to write a [parser](https://en.wikipedia.org/wiki/Parsing#Parser), which needs to be fed [tokens](https://en.wikipedia.org/wiki/Lexical_analysis#Token). We will do that by creating a tokenizer or a [lexer](https://en.wikipedia.org/wiki/Lexical_analysis). We will create a class called `Token` will consist of two variables: 
- `type`: The type of the token.
- `value`: The string value of the token.

Firstly, however, we must define our token types; I will do that using an enum.
```python
class TokenType(Enum):
    # symbols
    LPAR = auto()       # (
    RPAR = auto()       # )
    LBRACE = auto()     # {
    RBRACE = auto()     # }
    SEMICOL = auto()    # ;
    COMMA = auto()      # ,
    ASSIGN = auto()     # =
    NOT = auto()        # !
    PLUS = auto()       # +
    MINUS = auto()      # -
    STAR = auto()       # *
    SLASH = auto()      # /
    EQ = auto()         # ==
    NE = auto()         # !=
    GT = auto()         # >
    GE = auto()         # >=
    LT = auto()         # <
    LE = auto()         # <=
    # keywords
    VAR = auto()        # var
    ID = auto()
    FUNC = auto()       # function
    RET = auto()        # return
    # literals
    INT_LITERAL = auto()
    FLOAT_LITERAL = auto()
    STRING_LITERAL = auto()
    # other
    NEWLINE = auto()
    UNKNOWN = auto()
    EOS = auto()        # signals the end of the source code; '\0' in c/c++
```
Now that we have our types, let's define our `Token` class:
```python
class Token:
    type: TokenType
    value: str
    
    def __init__(self, type: TokenType, value: str = ''):
        self.type = type
        self.value = value
```
And now we need to create our tokenizer, which will have the following variables:
- `source`: The source code for what we're compiling.
- `length`: The length of the source code will be stored in this variable to reduce the number of calls to `len()`.
- `pos`: To indicate the position of the tokenizer.
- `line` and `col`: For error feedback.

Now, we will create our `Token` class:
```python
    source: str
    length: int
    pos: int
    line: int = 0
    col: int = 0
    
    def __init__(self, source: str):
        self.source = source
        self.pos = 0
        self.line = 0
        self.col = 0
        self.length = len(source)
    
    def getToken(self) -> Token:
        pass

    def getId(self) -> Token:
        pass

    def getNumber(self) -> Token:
        pass

    def getString(delim: str, self) -> Token:
        pass

    def getSymbol(self) -> Token:
        pass
```
The method `getToken()` will return a token generated from the source code. Let's define it: (remember to keep the definitions inside the class if you're using python)
```python
def getToken(self) -> Token:
    while self.pos < self.length:
        while self.source[self.pos] == ' ' or self.source[self.pos] == '\t':
            self.pos += 1
            self.col += 1
        return self.getSymbol()
    return Token(TokenType.EOS)
```
As you can see, `Tokenizer.getToken()` will return `getSymbol()` as long as `pos` is within `source`'s range. Else, it will return the `end of source` endmarker, `TokenType.EOS`. As you may have noticed will also skip whitespace, since we don't need whitespace for our programming language.
Now let's define `Tokenizer.getSymbol()`:
```python
def getSymbol(self) -> Token:
    def initToken(type: TokenType, value: str):
        self.pos += 1
        self.col += 1
        return Token(type, value)
        
    if self.pos == self.length:
        return Token(TokenType.EOS)

    current = self.source[self.pos]
    if current.isdigit():
        return self.getNumber()
    elif current.isalpha():
        return self.getId()

    match current:
        case '\n':
            self.line += 1
            self.col = 0
            self.pos += 1
            return Token(TokenType.NEWLINE)
        case ['\'', '"']:
            return self.getString()
        case '(':
            return initToken(TokenType.LPAR, '(')
        case ')':
            return initToken(TokenType.RPAR, ')')
        case '{':
            return initToken(TokenType.LBRACE, '{')
        case '}':
            return initToken(TokenType.RBRACE, '}')
        case ';':
            return initToken(TokenType.SEMICOL, ';')
        case ',':
            return initToken(TokenType.COMMA, ',')
        case '+':
            return initToken(TokenType.PLUS, '+')
        case '-':
            return initToken(TokenType.MINUS, '-')
        case '*':
            return initToken(TokenType.STAR, '*')
        case '/':
            return initToken(TokenType.SLASH, '/')
        case '=':
            self.pos += 1
            self.col += 1
            if self.source[self.pos] == '=':
                return initToken(TokenType.EQ, '==')
            return Token(TokenType.ASSIGN, '=')
        case '!':
            self.pos += 1
            self.col += 1
            if self.source[self.pos] == '=':
                return initToken(TokenType.NE, '!=')
            return Token(TokenType.NOT, '!')
        case '>':
            self.pos += 1
            self.col += 1
            if self.source[self.pos] == '=':
                return initToken(TokenType.GE, '>=')
            return Token(TokenType.GT, '>')
        case '<':
            self.pos += 1
            self.col += 1
            if self.source[self.pos] == '=':
                return initToken(TokenType.LE, '<=')
            return Token(TokenType.LT, '<')
        case _:
            compilerError(self.line, self.col, "unexpected token")
```
I'm using python 3.10, which supports pattern matching with `match`, but if your language doesn't support it, you can stick with regular if-elses. With that out of the way, you can see that `Tokenizer.getSymbol()` returns a symbol/character, but if it encounters a digit or an alphabetical character, it returns `Tokenizer.getNumber()` or `Tokenizer.getId()` respectively. It will also return `Tokenizer.getString()` if it encounters a `'` or `"`. Let's define those functions:
```python
def getId(self) -> Token:
    value = ''
    while self.pos < self.length and \
        (self.source[self.pos].isalnum() or self.source[self.pos] == '_'):
        value += self.source[self.pos]
        self.pos += 1
        self.col += 1
    if value == 'var':
        return Token(TokenType.VAR, value)
    elif value == 'function':
        return Token(TokenType.FUNC, value)
    elif value == 'return':
        return Token(TokenType.RET, value)
    return Token(TokenType.ID, value)

def getNumber(self) -> Token:
    value = ''
    dot = False
    while self.pos < self.length and \
        (self.source[self.pos].isdigit() or self.source[self.pos] == '.'):
        if self.source[self.pos] == '.':
            if dot:
                compilerError(self.line, self.col, 'Unexpected \'.\'')
            dot = True
        value += self.source[self.pos]
        self.pos += 1
        self.col += 1
    if dot:
        return Token(TokenType.FLOAT_LITERAL, value)
    return Token(TokenType.INT_LITERAL, value)

def getString(delim: str, self) -> Token:
    value = ''
    self.pos += 1
    self.col += 1
    while self.pos < self.length and self.source[self.pos] != delim:
        value += self.source[self.pos]
        self.pos += 1
        self.col += 1
    self.pos += 1
    self.col += 1
    return Token(TokenType.STRING_LITERAL, value)
```
Now that we defined all our functions, our code should look something like this:
```python
import sys
from enum import Enum, auto
from typing import Any

def compilerError(message: str):
    print('Error: ' + message)
    exit(1)

def compilerError(line: int, col: int, message: str):
    print(f'Error (line {line}, col {col}): {message}', file=sys.stderr)
    exit(1)

class TokenType(Enum):
    # symbols
    LPAR = auto()       # (
    RPAR = auto()       # )
    LBRACE = auto()     # {
    RBRACE = auto()     # }
    SEMICOL = auto()    # ;
    COMMA = auto()      # ,
    ASSIGN = auto()     # =
    NOT = auto()        # !
    PLUS = auto()       # +
    MINUS = auto()      # -
    STAR = auto()       # *
    SLASH = auto()      # /
    EQ = auto()         # ==
    NE = auto()         # !=
    GT = auto()         # >
    GE = auto()         # >=
    LT = auto()         # <
    LE = auto()         # <=
    # keywords
    VAR = auto()        # var
    ID = auto()
    FUNC = auto()       # function
    RET = auto()        # return
    # literals
    INT_LITERAL = auto()
    FLOAT_LITERAL = auto()
    STRING_LITERAL = auto()
    # other
    NEWLINE = auto()
    UNKNOWN = auto()
    EOS = auto()        # signals the end of the source code; '\0' in c/c++

class Token:
    type: TokenType
    value: str
    
    def __init__(self, type: TokenType, value: str = ''):
        self.type = type
        self.value = value
    
class Tokenizer:
    source: str
    length: int
    pos: int
    line: int = 0
    col: int = 0
    
    def __init__(self, source: str):
        self.source = source
        self.pos = 0
        self.line = 0
        self.col = 0
        self.length = len(source)
    
    def getToken(self) -> Token:
        while self.pos < self.length:
            while self.source[self.pos] == ' ' or self.source[self.pos] == '\t':
                self.pos += 1
                self.col += 1
            return self.getSymbol()
        return Token(TokenType.EOS)

    def getId(self) -> Token:
        value = ''
        while self.pos < self.length and \
            (self.source[self.pos].isalnum() or self.source[self.pos] == '_'):
            value += self.source[self.pos]
            self.pos += 1
            self.col += 1
        if value == 'var':
            return Token(TokenType.VAR, value)
        elif value == 'function':
            return Token(TokenType.FUNC, value)
        elif value == 'return':
            return Token(TokenType.RET, value)
        return Token(TokenType.ID, value)

    def getNumber(self) -> Token:
        value = ''
        dot = False
        while self.pos < self.length and \
            (self.source[self.pos].isdigit() or self.source[self.pos] == '.'):
            if self.source[self.pos] == '.':
                if dot:
                    compilerError(self.line, self.col, 'Unexpected \'.\'')
                dot = True
            value += self.source[self.pos]
            self.pos += 1
            self.col += 1
        if dot:
            return Token(TokenType.FLOAT_LITERAL, value)
        return Token(TokenType.INT_LITERAL, value)

    def getString(delim: str, self) -> Token:
        value = ''
        self.pos += 1
        self.col += 1
        while self.pos < self.length and self.source[self.pos] != delim:
            value += self.source[self.pos]
            self.pos += 1
            self.col += 1
        self.pos += 1
        self.col += 1
        return Token(TokenType.STRING_LITERAL, value)

    def getSymbol(self) -> Token:
        def initToken(type: TokenType, value: str):
            self.pos += 1
            self.col += 1
            return Token(type, value)
        
        if self.pos == self.length:
            return Token(TokenType.EOS)

        current = self.source[self.pos]
        if current.isdigit():
            return self.getNumber()
        elif current.isalpha() or current == '_':
            return self.getId()

        match current:
            case '\n':
                self.line += 1
                self.col = 0
                self.pos += 1
                return self.getToken()
            case ['\'', '"']:
                return self.getString()
            case '(':
                return initToken(TokenType.LPAR, '(')
            case ')':
                return initToken(TokenType.RPAR, ')')
            case '{':
                return initToken(TokenType.LBRACE, '{')
            case '}':
                return initToken(TokenType.RBRACE, '}')
            case ';':
                return initToken(TokenType.SEMICOL, ';')
            case ',':
                return initToken(TokenType.COMMA, ',')
            case '+':
                return initToken(TokenType.PLUS, '+')
            case '-':
                return initToken(TokenType.MINUS, '-')
            case '*':
                return initToken(TokenType.STAR, '*')
            case '/':
                return initToken(TokenType.SLASH, '/')
            case '=':
                self.pos += 1
                self.col += 1
                if self.source[self.pos] == '=':
                    return initToken(TokenType.EQ, '==')
                return Token(TokenType.ASSIGN, '=')
            case '!':
                self.pos += 1
                self.col += 1
                if self.source[self.pos] == '=':
                    return initToken(TokenType.NE, '!=')
                return Token(TokenType.NOT, '!')
            case '>':
                self.pos += 1
                self.col += 1
                if self.source[self.pos] == '=':
                    return initToken(TokenType.GE, '>=')
                return Token(TokenType.GT, '>')
            case '<':
                self.pos += 1
                self.col += 1
                if self.source[self.pos] == '=':
                    return initToken(TokenType.LE, '<=')
                return Token(TokenType.LT, '<')
            case _:
                compilerError(self.line, self.col, "unexpected token")
```
Let's test it by adding this to our code:
```python
tokenizer = Tokenizer('''
function hello() {
    var hi = 123;
    return hi;
}
''')
while 1:
    tok = tokenizer.getToken()
    if tok.type == TokenType.EOS:
        break
    print(repr(tok.type) + ' ' + tok.value)
```
We should get output that looks like this:
```
<TokenType.NEWLINE: 25> 
<TokenType.FUNC: 20> function
<TokenType.ID: 19> hello
<TokenType.LPAR: 1> (
<TokenType.RPAR: 2> )
<TokenType.LBRACE: 3> {
<TokenType.NEWLINE: 25>
<TokenType.VAR: 18> var
<TokenType.ID: 19> hi
<TokenType.ASSIGN: 6> =
<TokenType.INT_LITERAL: 22> 123
<TokenType.SEMICOL: 5> ;
<TokenType.NEWLINE: 25>
<TokenType.RET: 21> return
<TokenType.ID: 19> hi
<TokenType.SEMICOL: 5> ;
<TokenType.NEWLINE: 25>
<TokenType.RBRACE: 4> }
<TokenType.NEWLINE: 25>
```
Congratulations, we have now finished writing our tokenizer.
### Part Two: The Parser <a name="parser"></a>
The next step after finishing our tokenizer is to define AST classes for our parser to generate. Like the tokens, the first step is to define our AST types:
```python
class AstType(Enum):
    kStatement = auto()
    kExpression = auto()
    kAssignment = auto()
    kFunction = auto()
    kReturn = auto()
    kBinaryOperation = auto()
    kLiteral = auto()
    kName = auto()
```
Since we're interpreting a very basic program, these are all the node types we need. Now to define the base classes for our ASTs.

> **_Note:_** the language you're programming in may not support classes or inheritance. In that case, you might want to create a union that holds all the AST structures.
```python
class AstNode:
    type: AstType
    def __init__(self, type: AstType):
        self.type = type

class Statement(AstNode):
    def __init__(self, type:AstType):
        super().__init__(type)
        
class Expression(AstNode):
    def __init__(self, type:AstType):
        super().__init__(type)
```
And now we can define the rest of our ASTs. Let's start with `Assignment`:
```python
class Assignment(Statement):
    target: str
    value: Expression

    def __init__(self, target: str, value: Expression):
        super().__init__(AstType.kAssignment)
        self.target = target
        self.value = value
```
And `Function`:
```python
class Function(Statement):
    name: str
    params: list[Expression]
    body: list[Statement]

    def __init__(self, name:str, params: list[Expression], body: list[Statement]):
        super().__init__(AstType.kFunction)
        self.name = name
        self.params = params
        self.body = body
```
And `Return`:
```python
class Return(Statement):
    value: Expression

    def __init__(self, value:Expression):
        super().__init__(AstType.kReturn)
        self.value = value
```
That's all we need for our `Statement`s. Now let's define our `Expression` classes: `BinaryOperation` and `Literal`. We'll start off with `BinaryOperation`:
```python
class BinaryOperation(Expression):
    op: TokenType
    left: Expression
    right: Expression

    def __init__(self, op: TokenType, left: Expression, right: Expression):
        super().__init__(AstType.kBinaryOperation)
        self.op = op
        self.left = left
        self.right = right
```
Now that we have finished that, let's define our `Literal` class. Before that, we must create an enum containing the types of `Literal`s. We only need three so far:
```python
class LiteralType(Enum):
    INTEGER = auto()
    FLOAT = auto()
    STRING = auto()
```
And now, we can define our `Literal` class:
```python
class Literal(Expression):
    literaltype: LiteralType
    value: Any

    def __init__(self, type: LiteralType, value: Any):
        super().__init__(AstType.kLiteral)
        self.literaltype = type
        self.value = value
```
The only node we have to define now is `Name`, which is pretty simple:
```python
class Name(Expression):
    name: str
    is_param: bool

    def __init__(self, name: str, is_param: bool):
        super().__init__(AstType.kName)
        self.name = name
        self.is_param = is_param
```
Great, now that we have finished defining all our AST nodes, we can define our `Parser` class. It will only need two variables:
- `source`: A `Tokenizer` that will feed the parser tokens.
- `current`: The current token the parser is at.
```python
class Parser:
    source: Tokenizer
    current: Token

    def __init__(self, source: Tokenizer):
        self.source = source
        self.current = self.source.getToken()

    def __init__(self, source: Tokenizer):
        self.source = source
        self.current = self.source.getToken()

    def next(self):
        self.current = self.source.getToken()

    def expect(self, type: TokenType):
        if self.current.type != type:
            compilerError(self.source.line, self.source.col, "expected a " + repr(type))
        self.next()
        
    def parseProgram(self) -> list[Statement]:
        pass
    
    def parseItem(self) -> Statement:
        pass
        
    def parseFunction(self) -> Statement:
        pass
    
    def parseReturn(self) -> Statement:
        pass
        
    def parseAssignment(self) -> Statement:
        pass
    
    def parseFactor(self) -> Expression:
        pass

    def parseTerm(self) -> Expression:
        pass

    def parseExpression(self) -> Expression:
        pass
```

Now, we'll start defining the functions. I'll start with `Parser.parseProgram()` and `Parser.parseItem()`:
```python
def parseProgram(self) -> list[Statement]:
    result = []
    while self.current.type != TokenType.EOS:
        result.append(self.parseItem())
    return result

def parseItem(self) -> Statement:
    match self.current.type:
        case TokenType.FUNC:
            return self.parseFunction()
        case TokenType.RET:
            return self.parseReturn()
        case TokenType.VAR:
            return self.parseAssignment()
        case _:
            compilerError(self.source.line, self.source.col, \
                "Expected a statement, recieved " + repr(self.current.type))
```
As you can see, `Parser.parseProgram()` will append `Parser.parseItem()` to a list as long as the current token is not an endmarker. As for `Parser.parseItem()`, it will return a function based on the type of the current token. Now to define `Parser.parseFunction()`, which will consist of three variables: 
- `id`: A string which will contain the function's name.
- `args`: A list that will contain the function's parameters.
- `body`: A list of `Statement`s that will contain the function's body.

We will use follow the following grammar for our language's function definition:
```
function <name>(<parameters>) {
    <body>
}
```
While we're at it, we'll also define `Parser.parseReturn()`
```python
def parseParam(self) -> Expression:
    name = self.current.value
    self.next()
    return Name(name, True)

def parseFunction(self) -> Statement:
    self.expect(TokenType.FUNC)
    id = self.current.value
    self.next()
    self.expect(TokenType.LPAR)
    args = []
    if self.current.type == TokenType.VAR:
        self.expect(TokenType.VAR)
        args.append(parseParam())
    while self.current.type == TokenType.COMMA:
        self.expect(TokenType.COMMA)
        self.expect(TokenType.VAR)
        args.append(parseParam())
    self.expect(TokenType.RPAR)
    body = []
    self.expect(TokenType.LBRACE)
    while self.current.type != TokenType.RBRACE:
        body.append(self.parseItem())
    self.expect(TokenType.RBRACE)
    return Function(id, args, body)

def parseReturn(self) -> Statement:
    self.expect(TokenType.RET)
    value = self.parseExpression()
    self.expect(TokenType.SEMICOL)
    return Return(value)
```
The code should've been pretty self-explanatory. Now for `Parser.parseAssignment()`. We'll use the following grammar for our language's assignment: `var <name> = <value>;`
```python
def parseAssignment(self) -> Statement:
    self.expect(TokenType.VAR)
    id = self.current.value
    self.expect(TokenType.ID)
    self.expect(TokenType.ASSIGN)
    value = self.parseExpression()
    self.expect(TokenType.SEMICOL)
    return Assignment(id, value)
```
Now to move on to expressions. We'll do that by using three functions: `Parser.parseFactor()`, `Parser.parseTerm()` and `Parser.parseExpression()`.
```python
 def parseFactor(self) -> Expression:
    match self.current.type:
        case TokenType.LPAR:
            self.next()
            value = self.parseExpression()
            self.expect(TokenType.RPAR)
            return value
        case TokenType.ID:
            id = self.current.value
            self.next()
            return Name(id, False)
        case TokenType.INT_LITERAL:
            value = int(self.current.value)
            self.next()
            return Literal(LiteralType.INTEGER, value)
        case TokenType.FLOAT_LITERAL:
            value = float(self.current.value)
            self.next()
            return Literal(LiteralType.FLOAT, value)
        case TokenType.STRING_LITERAL:
            value = self.current.value
            self.next()
            return Literal(LiteralType.STRING, value)
        case _:
            compilerError(self.source.line, self.source.col, \
                "Expected an expression, recieved " + repr(self.current.type))

def parseTerm(self) -> Expression:
    node = self.parseFactor()
    while self.current.type == TokenType.STAR or self.current.type == TokenType.SLASH:
        op = self.current.type
        self.next()
        node = BinaryOperation(op, node, self.parseFactor())
    return node

def parseExpression(self) -> Expression:
    node = self.parseTerm()
    while self.current.type == TokenType.PLUS or self.current.type == TokenType.MINUS:
        op = self.current.type
        self.next()
        node = BinaryOperation(op, node, self.parseTerm())
    return node
    
```
And with that, we've finished our parser.
#### Part 2.5: A (Not-So-Well Made) AST Printer
This part is optional, but I will include a definition for an `AstPrinter` class that will print a list of ASTs that the parser generates. Since it's not a big part of the code it will be offered without explanation, but you should get the basic idea: (also, we finally utilize our `print_raw` instruction, yay)
```python
class AstPrinter:
    def printAst(self, list: list[Statement]):
        for node in list:
            self.doPrintAst(node)

    def doPrintAst(self, node: AstNode):
        match node.type:
            case AstType.kAssignment:
                assignment: Assignment = node
                print_raw(f'Assignment(Name=\'{assignment.target}\', Value=')
                self.doPrintAst(assignment.value)
            case AstType.kBinaryOperation:
                binop: BinaryOperation = node
                print_raw(f'BinaryOperation(Operation={binop.op}, Left=')
                self.doPrintAst(binop.left)
                print_raw(f', Right=')
                self.doPrintAst(binop.right)
            case AstType.kFunction:
                function: Function = node
                print_raw(f'Function(Name=\'{function.name}\', Parameters=(')
                for param in function.params:
                    self.doPrintAst(param)
                    print_raw(', ')
                print_raw(f'\b\b), Body=(')
                for stmt in function.body:
                    self.doPrintAst(stmt)
                    print_raw(', ')
                print_raw('\b\b)')
            case AstType.kLiteral:
                literal: Literal = node
                print_raw(f'Literal(Value={literal.value})')
            case AstType.kName:
                name: Name = node
                print_raw(f'Name(IsParam={name.is_param}, Value=\'{name.name}\')')
            case AstType.kReturn:
                ret: Return = node
                print_raw(f'Return(Value=')
                self.doPrintAst(ret.value)
                print_raw(')')
            case _:
                print_raw('[error]')
```
We can use it like this:
```python
test = Parser(Tokenizer('''
function main(var bob, var bill) {
    var hello = bob * bill + bob * bill;
    return hello;
}
'''))
printer = AstPrinter()
printer.printAst(test.parseProgram())

```

### Part Three: Understanding How the Virtual Machine Will Work <a name="vm"></a>
Before we write our bytecode generator, we must understand how the virtual machine/interpreter will work:
#### The Entry Point
The interpreter will execute a function called the entry point, much like `int main()` in C/C++.
#### Bytecode
The bytecode will be a series of instructions and arguments for the virtual machine to execute.
#### The Constant Pool
In order for the vm to load constants, it needs a constant pool. The constant pool will be a list composed of constants used throughout the program.
#### The Stack
Our interpreter will be a [stack-based virtual machine](https://en.wikipedia.org/wiki/Stack_machine), which means it will utilize a [stack](https://en.wikipedia.org/wiki/Stack_(abstract_data_type)). It will work by pushing values onto the stack and running instructions on them. Consider this piece of bytecode:
```
ldconst. 0  # load constant from index 0 in the constant pool
ldconst. 1  # load constant from index 1 in the constant pool
add         # pop the two value on the top of the stack and push the result
```
Let's see what each instruction does to the stack:
|Top of Stack|
|-|

`ldconst 0`: Load constant from index 0 in the constant pool. Let's assume the constant at index 0 is `34`

|Top of Stack|
|-|
|34|

`ldconst 1`: Load constant from index 1 in the constant pool. Let's assume the constant at index 1 is `35`

|Top of Stack|
|-|
|35|
|34|

`add`: Pop the two values on the top of the stack and push the result.

|Top of Stack|
|-|
|69|

Hopefully, that example gave you some insight on how the vm works. Now that we've gotten the basic idea, let's start writing the bytecode generator.
### Part Four: Code Generation <a name="code-generation"></a>
Before we begin to write our bytecode generator, we should define our instructions:
```python
class Instruction(Enum):
    ldconst = auto()
    ldloc = auto()
    ldarg = auto()
    stloc = auto()
    call = auto()
    add = auto()
    sub = auto()
    mul = auto()
    div = auto()
    ret = auto()
```
Here is what each instruction will do:
| Instruction | Operation |
|-------------|-------------------------------------------------------------------|
| ldconst (*i*) | Pushes constant at index *i* from the constant pool onto the stack. |
| ldloc (*i*) | Pushes the value of the local variable at index *i* from the local variable table onto the stack. |
| ldarg (*i*) | Pushes the argument *i* from the argument table onto the stack. |
| stloc (*i*) | Stores the value on the top of the stack into the local variable table at index *i*. |
| call (*i*) | Calls function *i* from the list of functions. |
| add | Pops the two values on the top of the stack and pushes the sum. |
| sub | Pops the two values on the top of the stack and pushes the difference. |
| mul | Pops the two values on the top of the stack and pushes the product. |
| div | Pops the two values on the top of the stack and pushes the quotient. |
| ret | Returns from the function that is currently executing. |

Now we need to define our `RuntimeConstant` class, which is what `ldconst` will need to operate.
```python
class RuntimeConstant:
    type: RuntimeConstantType
    value: Any

    def __init__(self, type: RuntimeConstantType, value: Any):
        self.type = type
        self.value = value
```
And our `RuntimeVariable` class to store variables in during execution:
```python
class RuntimeVariable:
    name: str
    value: RuntimeConstant

    def __init__(self, name: str, value: RuntimeConstant):
        self.name = name
        self.value = value
```
That was pretty simple. Let's define our `FunctionObject` for our interpreter to run:
```python
class FunctionObject:
    name: str
    instructions: list[Instruction]
    local_variables: list[RuntimeVariable]

    def __init__(self, name: str, instructions: list[Instruction]):
        self.name = name
        self.instructions = instructions
        self.local_variables = []
```
As you can see, `FunctionObject` consists of:
- `name`: The function's name
- `instructions`: The function's instructions
- `local_variables`: A list of `RuntimeVariables` to be used locally within the function

And now for our `Bytecode` class, which will contain the following variables:
- `functions`: A list of `FunctionObjects` (functions).
- `entrypoint`: The function to be executed when the interpreter runs.
- `constant_pool`: A list of `RuntimeConstant`s that will act as the constant pool.
```python
class Bytecode:
    functions: list[FunctionObject]
    entrypoint: FunctionObject
    constant_pool: list[RuntimeConstant]

    def __init__(self, functions: list[FunctionObject], entrypoint: FunctionObject, constant_pool: list[RuntimeConstant]):
        self.functions = functions
        self.entrypoint = entrypoint
        self.constant_pool = constant_pool
```
We can now get started on writing our compiler. It will have these variables:
- `tree`: A list of `AstNode`s generated from the parser.
- `functions`: A list of `FunctionObject`s the compiler will store functions in until it's time to build the `Bytecode`
- `current_function`: The function the compile is currently generating.
- `entry_point`: The function to be executed when the interpreter runs (we're holding it in this variable until it's time to build our `Bytecode`).
- `constants`: A list of `RuntimeConstant`s for `Instruction.ldconst` to load constants from.
- `variable_map`: A list of variables so we can get their indexes to pass onto `Instruction.ldloc`. It will be cleared every time we visit a function AST.
- `argument_map`: Same thing as `variable_map`, but for arguments.
```python
class Compiler:
    tree: list[AstNode]
    functions: list[FunctionObject]
    current_function: FunctionObject
    entry_point: FunctionObject
    constants: list[RuntimeConstant]
    variable_map: list[str]
    argument_map: list[str]

    def __init__(self, source: str):
        parser = Parser(Tokenizer(source))
        self.tree = parser.parseProgram()
        self.functions = []
        self.current_function = None
        self.entry_point = None
        self.constants = []
        self.variable_map = []
        self.argument_map = []
    
    def compile(self):
        for node in self.tree:
            self.visit(node)
        return Bytecode(self.functions, self.entry_point, self.constants)
    
    def emit(self, instruction: Instruction):
        assert self.current_function != None
        self.current_function.instructions.append(instruction)
    
    def addConstant(self, constant: RuntimeConstant):
        for const in self.constants:
            if const == constant:
                return self.constants.index(const)
        self.constants.append(constant)
        return len(self.constants) - 1
    
    def addName(self, name: str):
        for var in self.variable_map:
            if var == name:
                return self.variable_map.index(var)
        self.variable_map.append(name)
        return len(self.variable_map) - 1
    
    def addArg(self, argument: str):
        for arg in self.argument_map:
            if arg == argument:
                return self.argument_map.index(arg)
        self.argument_map.append(argument)
        return len(self.argument_map) - 1

    def visit(self, node: AstNode):
        match node.type:
            case AstType.kAssignment:
                return self.visitAssignment(node)
            case AstType.kFunction:
                return self.visitFunction(node)
            case AstType.kReturn:
                return self.visitReturn(node)
            case AstType.kBinaryOperation:
                return self.visitBinaryOperation(node)
            case AstType.kLiteral:
                return self.visitLiteral(node)
            case AstType.kName:
                return self.visitName(node)
            case _:
                print('unreachable code reached')
                exit(1)

    def visitAssignment(self, node: Assignment):
        pass

    def visitFunction(self, node: Function):
        pass

    def visitReturn(self, node: Return):
        pass

    def visitBinaryOperation(self, node: BinaryOperation):
        pass

    def visitLiteral(self, node: Literal):
        pass

    def visitName(self, node: Name):
        pass
```
As you can probably tell by now, the `Compiler` class takes a string as a source and initializes the `tree` member. To get the bytecode, we must call `Compiler.compile()`, which iteratively visits each node in the tree and returns a `Bytecode`. Since, our programming language needs an entry point to run, let's start off by defining `Compiler.visitFunction()`:
```python
def visitFunction(self, node: Function):
    self.current_function = FunctionObject(node.name, [])
    for stmt in node.body:
        self.visit(stmt)
    if self.current_function.instructions[len(self.current_function.instructions) - 1] != Instruction.ret:
        self.emit(self.addConstant(RuntimeConstant(RuntimeConstantType.RTC_UNDEF, None)))
        self.emit(Instruction.ret)
    if node.name == 'main':
        if self.entry_point != None:
            compilerError('redefinition of \'main\'')
        self.entry_point = self.current_function
        self.current_function = None
    else:
        for func in self.functions:
            if func.name == self.current_function.name:
                compilerError(f'redefinition of \'{func.name}\'')
        self.functions.append(self.current_function)
        self.current_function = None
```
Note that if the last instruction in the current function's body is not `Instruction.ret`, we load a `RuntimeConstant` with the type `RTC_UNDEF` and the value `None` because every function has to return something.

Now let's define `Compiler.visitAssignment()`.
```python
def visitAssignment(self, node: Assignment):
    self.visit(node.value)
    self.emit(Instruction.stloc)
    self.emit(self.addName(node.target))
```
As you can see, this function will call `Compiler.visit()` on the assignment's value and then emits `stloc` to the bytecode array of the current function along with it's integer argument: the position of the variable on the variable map, after  the interpreter uses an array to store the variables. Now let's define `Compiler.visitReturn`:
```python
def visitReturn(self, node: Return):
    self.visit(node.value)
    self.emit(Instruction.ret)
```
Since we've gotten all the statements handles, let's move onto the expressions. We'll start with `Compiler.visitBinaryOperation()`:
```python
    def visitBinaryOperation(self, node: BinaryOperation):
        self.visit(node.left)
        self.visit(node.right)
        match node.op:
            case TokenType.PLUS:
                self.emit(Instruction.add)
            case TokenType.MINUS:
                self.emit(Instruction.sub)
            case TokenType.STAR:
                self.emit(Instruction.mul)
            case TokenType.SLASH:
                self.emit(Instruction.div)
```
Now to define `Compiler.visitLiteral()`, `Compiler.visitName()`, both of which will do similar things:
```python
    def visitLiteral(self, node: Literal):
        self.emit(Instruction.ldconst)
        self.emit(self.addConstant(node.value))

    def visitName(self, node: Name):
        if node.is_param:
            self.emit(Instruction.ldarg)
            self.emit(self.addArg(node.name))
        else:
            self.emit(Instruction.ldloc)
            self.emit(self.addName(node.name))
```
And with that, we've finished the bytecode generator. We can test it by adding the following code:
```
function main() {
    var somevar = 100 + 50;
    return somevar;
}
```
> **_Note:_** The source code we're compiling **must** have the "main" function. This is because we use the name "main" as the entry point, which means that if we don't have a "main" function, we're going to have an undefined value for the entrypoint returned by the compiler, which we can't iterate. Why iterate? Because we want to print the bytecode to get some insight on how the compiler works.

```python
test = Compiler('''
function main() {
    var somevar = 100 + 50;
    return somevar;
}
''')
res = test.compile()
for _ in res.entrypoint.instructions:
    print(_)
```
The generated bytecode for the entry point should be as follows:
```
ldconst. 0
ldconst. 1
add
stloc. 0
ldloc. 0
ret
```
What do you think the bytecode will be for this program? (You can compile this as well to find out)
```js
function main(var param1, var param2) {
    var result = param1 * param2 + param1 * param2;
    return result;
}
```
### The Virtual Machine <a name="vm"></a>
### Coming Soon
